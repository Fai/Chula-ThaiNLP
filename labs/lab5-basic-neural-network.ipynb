{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Feedforward Neural Network "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3f86a807e7a0f98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for colab version supported\n",
    "# %tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from IPython.display import Image, display_png\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, Flatten, GlobalAveragePooling1D\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3363c59105a0d7d7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Load up the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "555483f5eec42c96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!gdown --id 14l7wuSNFg0KEberTf-LoniKle4k2bQMa\n",
    "!upzip wongnai-data.zip"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c12f0ab21590455"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('wongnai-tain.csv', encoding='utf-8')\n",
    "dev = pd.read_csv('wongnai-dev.csv', encoding='utf-8')\n",
    "\n",
    "# show data\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce729ed51fdd1cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# add column 'length'\n",
    "train['length'] = train['tokenized'].apply(lambda x: x.count('|'))\n",
    "dev['length'] = dev['tokenized'].apply(lambda x: x.count('|'))\n",
    "\n",
    "dev"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8990a951f0067bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "ส่วนใหญ่มีแค่ 100 คำ ไม่ต้องใช้ทั้งหมด"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7def1f90492a49fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train.length.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3b140a37651c97f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dev.length.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b4310cff7cb3e47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Load up the pre-trained word embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fba8d51409e55e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!gdown --id 14bv_aTSP-8rs_Bkudvpp8zcU3UpyRen6 #TNC_embeddings-100.bin"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92a0fe177cc11c56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format('TNC_embeddings-100.bin', binary=True, unicode_errors='ignore')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "267608474069add4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# vocabulary size of pre-trained model\n",
    "vocab_size = len(w2v_model.wv.vocab)\n",
    "print(\"vocab size:\", vocab_size)\n",
    "\n",
    "# word vector dimension\n",
    "vector_dim = len(w2v_model['ไป'])\n",
    "print(\"vector dimension:\", vector_dim)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7804e809e11558f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# make weight matrix of word embedding, vocab size + 1 (for padding)\n",
    "embedding_matrix = np.zeros((vocab_size+1, vector_dim), dtype='float32')\n",
    "embedding_matrix[0] = np.zeros(vector_dim)\n",
    "\n",
    "word_to_index = {word:i+1 for i, word in enumerate(w2v_model.vocab)}\n",
    "# word to index dictionary, 0 for padding and UNKNOWN\n",
    "word_to_index['PADDING'] = 0\n",
    "\n",
    "for i, word in enumerate(w2v_model.vocab):\n",
    "    embedding_matrix[i+1] = w2v_model[word]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33517075c1361ad8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# example\n",
    "word_to_index['ไป']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68cce86fab9e393b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Convert words to indices and pad + truncate sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10c46cbd1ad4fd39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert_words(df, word_to_index, max_length):\n",
    "    tokens = df['tokenized'].apply(lambda x: x.split('|'))\n",
    "    list_of_list_of_indices = list(tokens.map(lambda x: [word_to_index.get(word, word_to_index['UNKNOWN']) for word in x]))\n",
    "    return pad_sequences(list_of_list_of_indices, maxlen=max_length, padding='post', truncating='post', value=0)\n",
    "\n",
    "# กำหนด max length เอง\n",
    "max_len = 500\n",
    "train_x = convert_words(train, word_to_index, max_len)\n",
    "dev_x = convert_words(dev, word_to_index, max_len)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445f5475b4274d1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_x[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebc363cccc034929"
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Mapping labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b14ea3e41a107f9d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_label(df):\n",
    "    star_to_label = {1: 0, 2: 0, 3: 1, 4: 1, 5: 2}\n",
    "    # apply functions & convert to np.array\n",
    "    label = np.array(df['star'].replace(star_to_label).tolist())\n",
    "    df['label'] = label\n",
    "    return to_categorical(label, num_classes=3)\n",
    "\n",
    "# label : one-hot vector\n",
    "train_y = get_label(train)\n",
    "dev_y = get_label(dev)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1691d1c097564cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_y[0:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d2018bf8457dd2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# check the shape (text, words) and (label)\n",
    "print('input train:', train_x.shape)\n",
    "print('input dev:', dev_x.shape)\n",
    "print(\"label train:\", train_y.shape)\n",
    "print(\"label dev:\", dev_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd40729890322b98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73430a0a94f5522"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# instantiation\n",
    "model = Sequential()\n",
    "\n",
    "# add embedding layer - mask_zero ignore padding\n",
    "model.add(Embedding(input_dim=vocab_size+1, output_dim=vector_dim, input_length=max_len, weights=[embedding_matrix], trainable=False, mask_zero=True))\n",
    "\n",
    "# average\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# add hidden layer - usually set equal to or less than embedding dimension\n",
    "model.add(Dense(150, activation='relu'))\n",
    "\n",
    "# add output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fd94e6edc1bc3c4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='model.png')\n",
    "display_png(Image('model.png'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad8506fe833c43ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# train - epochs is how many times the model will see the entire training set\n",
    "history = model.fit(train_x, train_y, batch_size=128, epochs=10, validation_data=(dev_x, dev_y))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "229a824048b5bc92"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# track accuracy in each epochs\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend({'train', 'dev'}, loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff26208bed8d4bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Evaluate the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "234c6425b56564ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prediction = [np.argmax(x) for x in model.predict(dev_x)]\n",
    "print(classification_report(dev['label'], prediction))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a22ac5ded6a2dce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
